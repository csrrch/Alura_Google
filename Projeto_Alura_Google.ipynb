{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1eYY86fTqxlvEyzEs8o6OESWcpSBh0i6b",
      "authorship_tag": "ABX9TyONL8BFJxxz1RFemBcomhgz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/csrrch/Alura_Google/blob/main/Projeto_Alura_Google.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Projeto: Imersão Alura Google\n",
        "\n",
        "Objetivo: Este projeto tem como objetivo, criar um resumo e responder questões a respeito de documentos e textos pessoais ou empresariais.\n",
        "\n",
        "Para este projeto iremos utilizar a técnica da Similaridade do Cosseno\n",
        "\n",
        "Restrições:\n",
        "  1. A execução deste projeto se dará apenas para um único arquivo\n",
        "  2. O arquivo tem que ser .txt\n",
        "\n",
        "Autor: Cesar Augusto Rocha\n",
        "\n",
        "Maio / 2024\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_Tx1IUU5fiHC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Bibliotecas a serem instaladas\n",
        "# !pip install nltk\n",
        "# !pip install pyttsx3"
      ],
      "metadata": {
        "id": "Lh0Qy0gxsMHg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyttsx3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9IiWKmUElqUV",
        "outputId": "04a3e61b-0bc2-4d6a-f005-e69924423d68"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyttsx3 in /usr/local/lib/python3.10/dist-packages (2.90)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyttsx3"
      ],
      "metadata": {
        "id": "dVAg7-7mnPqU"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importando bibliotecas\n",
        "\n",
        "import os\n",
        "import re\n",
        "import nltk\n",
        "import string\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "from IPython.display import HTML\n",
        "from nltk.cluster.util import cosine_distance\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Similaridade do Coseno\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from scipy.spatial.distance import cosine\n",
        "\n",
        "# Importando variáveis punkt e o pt_core_news_sm\n",
        "# Para tanto é necessário rodar a primeira vez o download\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LcuXHQ8RiVNp",
        "outputId": "5634bb66-1c97-40ef-8750-b8c200630054"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Definicoes das variáveis stopwords e strings\n",
        "stopwords = nltk.corpus.stopwords.words('portuguese')\n",
        "strings = string.punctuation"
      ],
      "metadata": {
        "id": "fnGpdA7owkrD"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Biblioteca para ligação com o Google Gemini\n",
        "import google.generativeai as genai"
      ],
      "metadata": {
        "id": "K6RPSownq4Ms"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Conectando com o Google Gemini\n",
        "from google.colab import userdata\n",
        "api_key_colab = userdata.get('SECRET_KEY')\n",
        "\n",
        "genai.configure(api_key=api_key_colab)\n",
        "\n"
      ],
      "metadata": {
        "id": "_oIHASpaprrx"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Atribuindo o caminho do arquivo\n",
        "path = \"/content/drive/MyDrive/Colab Notebooks/Assistente_Alura_Docs/Inteligencia_Artificial_ChatGPT.txt\""
      ],
      "metadata": {
        "id": "WwK2SP61rAC5"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Atribuindo o conteudo contido no documento à variável conteudo\n",
        "# conteudo = open(path, encoding='utf-8', errors = 'ignore').read().split('\\n')\n",
        "conteudo = open(path, encoding='utf-8', errors = 'ignore').read()\n"
      ],
      "metadata": {
        "id": "klaQEug4sBAY"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definicoes das funcoes\n",
        "\n",
        "# Preprocessamento do texto, realizando as limpezas necessárias para a tokenização\n",
        "def preprocessamento(texto):\n",
        "  texto_formatado = texto.lower()\n",
        "\n",
        "  # Retirando os espaços em branco\n",
        "  texto_formatado = re.sub(r'\\s+', ' ', texto_formatado)\n",
        "\n",
        "  tokens = []\n",
        "  for token in nltk.word_tokenize(texto_formatado):\n",
        "    tokens.append(token)\n",
        "\n",
        "  tokens = [palavra for palavra in tokens if palavra not in stopwords and palavra not in string.punctuation]\n",
        "  texto_formatado = ' '.join([str(elemento) for elemento in tokens if not elemento.isdigit()])\n",
        "\n",
        "  return texto_formatado\n"
      ],
      "metadata": {
        "id": "_XH9ReQEskvp"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# Similaridade do Cosseno - Sumarização\n",
        "#\n",
        "\n",
        "# Função para calcular a similaridade entre as sentencas\n",
        "def calcula_similaridade_sentencas(sentenca1, sentenca2):\n",
        "  palavras1 = [palavra for palavra in nltk.word_tokenize(sentenca1)]\n",
        "  palavras2 = [palavra for palavra in nltk.word_tokenize(sentenca2)]\n",
        "\n",
        "  todas_palavras = list(set(palavras1 + palavras2))\n",
        "\n",
        "  vetor1 = [0] * len(todas_palavras)\n",
        "  vetor2 = [0] * len(todas_palavras)\n",
        "\n",
        "  for palavra in palavras1:\n",
        "    vetor1[todas_palavras.index(palavra)] += 1\n",
        "  for palavra in palavras2:\n",
        "    vetor2[todas_palavras.index(palavra)] += 1\n",
        "\n",
        "  return 1 - cosine(vetor1, vetor2)\n",
        "\n",
        "# Função para calcular a matriz de similaridade enre as sentencas\n",
        "def calcula_matriz_similaridade(sentencas):\n",
        "  matriz_similaridade = np.zeros((len(sentencas), len(sentencas)))\n",
        "  #print(matriz_similaridade)\n",
        "  for i in range(len(sentencas)):\n",
        "    for j in range(len(sentencas)):\n",
        "      if i == j:\n",
        "        continue\n",
        "      matriz_similaridade[i][j] = calcula_similaridade_sentencas(sentencas[i], sentencas[j])\n",
        "\n",
        "  return matriz_similaridade\n",
        "\n",
        "# Função para sumarizar o texto\n",
        "def cosseno_sumarizar(texto, quantidade_sentencas):\n",
        "  sentencas_originais = [sentenca for sentenca in nltk.sent_tokenize(texto)]\n",
        "  sentencas_formatadas = [preprocessamento(sentenca_original) for sentenca_original in sentencas_originais]\n",
        "  matriz_similaridade = calcula_matriz_similaridade(sentencas_formatadas)\n",
        "  grafo_similaridade = nx.from_numpy_array(matriz_similaridade)\n",
        "  notas = nx.pagerank(grafo_similaridade)\n",
        "  notas_ordenadas = sorted(((notas[i], nota) for i, nota in enumerate(sentencas_originais)), reverse=True)\n",
        "  melhores_sentencas = []\n",
        "  for i in range(quantidade_sentencas):\n",
        "    melhores_sentencas.append(notas_ordenadas[i][1])\n",
        "\n",
        "  return sentencas_originais, melhores_sentencas, notas_ordenadas\n"
      ],
      "metadata": {
        "id": "ZcWJvr2Rjo2J"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Função para responder as perguntas do usuario\n",
        "def responder(texto_usuario):\n",
        "    resposta_chatbot = ''\n",
        "    conteudo_preprocessado = []\n",
        "    conteudo_preprocessado = sentencas_formatadas\n",
        "    conteudo_preprocessado.append(texto_usuario)\n",
        "\n",
        "    tfidf = TfidfVectorizer()\n",
        "    palavras_vetorizadas = tfidf.fit_transform(conteudo_preprocessado)\n",
        "\n",
        "    # Pegando a última frase da lista com o [-1]\n",
        "    similaridade = cosine_similarity(palavras_vetorizadas[-1], palavras_vetorizadas)\n",
        "\n",
        "    # Receber pegar um valor somente [-2]\n",
        "    indice_sentenca = similaridade.argsort()[0][-2]\n",
        "    vetor_similar = similaridade.flatten()\n",
        "    vetor_similar.sort()\n",
        "\n",
        "    # retornar o valor encontrado\n",
        "    vetor_encontrado = vetor_similar[-2]\n",
        "\n",
        "    if (vetor_encontrado == 0):\n",
        "        resposta_chatbot = resposta_chatbot + 'Desculpe, mas não entendi!'\n",
        "        return resposta_chatbot\n",
        "    else:\n",
        "        # print(indice_sentenca)\n",
        "        resposta_chatbot = resposta_chatbot + sentencas_originais[indice_sentenca]\n",
        "        return resposta_chatbot\n"
      ],
      "metadata": {
        "id": "CKNl5z-aIPYm"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configurando o modelo Gemini\n",
        "\n",
        "# candidate_count: qtde de informacoes de retorno\n",
        "# temperature: 0 - 1 = Aleatoreidade da retorno\n",
        "generation_config = {\n",
        "  \"candidate_count\": 1,\n",
        "  \"temperature\": 0.5,\n",
        "}\n",
        "\n",
        "# configuracoes de seguranca (safety settings)\n",
        "safety_settings={\n",
        "    'HATE': 'BLOCK_NONE',\n",
        "    'HARASSMENT': 'BLOCK_NONE',\n",
        "    'SEXUAL' : 'BLOCK_NONE',\n",
        "    'DANGEROUS' : 'BLOCK_NONE'\n",
        "    }"
      ],
      "metadata": {
        "id": "n37jWxMHpzAg"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iniciando o modelo\n",
        "model = genai.GenerativeModel(model_name='gemini-1.0-pro',\n",
        "                                  generation_config=generation_config,\n",
        "                                  safety_settings=safety_settings,)"
      ],
      "metadata": {
        "id": "E4zXs3mlp47U"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Criando o Chat\n",
        "\n",
        "chat = model.start_chat(history=[])"
      ],
      "metadata": {
        "id": "uf7kUDZ9rsQ2"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Código da Aplicação para criação das variáveis a serem utilizadas pelo Assistente\n",
        "\n",
        "# Fazendo a limpeza do conteudo e atribuindo a variavel texto_processado\n",
        "texto_processado = preprocessamento(conteudo)"
      ],
      "metadata": {
        "id": "KbeVD-CGux5Z"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gerando duas variaveis:\n",
        "# sentecas_originais = variavel tipo lista contendo o texto origial do documento\n",
        "sentencas_originais = [sentenca for sentenca in nltk.sent_tokenize(conteudo)]\n",
        "# sentencas_formadadas = variavel tipo lista contendo o texto tokenizado\n",
        "sentencas_formatadas = [preprocessamento(sentenca_original) for sentenca_original in sentencas_originais]\n"
      ],
      "metadata": {
        "id": "Pzf8Bn8yxoYY"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Escolhi 20% das sentenças para aplicar a sumarização\n",
        "qtd_sentenca = int(len(sentencas_originais)*0.20 + 1)\n",
        "\n",
        "sentencas_originais, melhores_sentencas, notas_sentencas = cosseno_sumarizar(conteudo, qtd_sentenca)\n"
      ],
      "metadata": {
        "id": "Mr7Cx0C_xLD6"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Imprimindo o Resumo do conteúdo\n",
        "\n",
        "display(HTML(f'<h1>Resumo do Arquivo</h1>'))\n",
        "display(HTML(f'<br>'))\n",
        "display(HTML(f'<h3>{path}</h3>'))\n",
        "display(HTML(f'<br>'))\n",
        "\n",
        "for sentenca in melhores_sentencas:\n",
        "   display(HTML(f\"{sentenca}\"))\n",
        "   display(HTML(f'<br>'))"
      ],
      "metadata": {
        "id": "Tz-hH2iT0Q6r",
        "outputId": "243c8047-dafe-49d0-b17c-602184e1f71a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<h1>Resumo do Arquivo</h1>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<h3>/content/drive/MyDrive/Colab Notebooks/Assistente_Alura_Docs/Inteligencia_Artificial_ChatGPT.txt</h3>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Principais Ferramentas de IA\n",
              "Algumas das principais ferramentas de IA incluem:\n",
              "- TensorFlow: Uma biblioteca de código aberto para aprendizado de máquina desenvolvida pelo Google."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Aplicações da IA\n",
              "A IA tem uma ampla gama de aplicações em diversos setores, incluindo medicina, finanças, manufatura, transporte, entretenimento e muito mais."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Principais Fornecedores de Tecnologia de IA\n",
              "Alguns dos principais fornecedores de tecnologia de IA incluem:\n",
              "- Google: Google Cloud AI, TensorFlow."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Renascimento da IA\n",
              "A virada do século XXI marcou um renascimento da IA, impulsionado por avanços no poder computacional, grandes conjuntos de dados e algoritmos de aprendizado de máquina."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Expansão e Desafios\n",
              "Nas décadas seguintes, a IA experimentou avanços significativos, incluindo o desenvolvimento de algoritmos de busca, sistemas especialistas e redes neurais artificiais."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "No entanto, o progresso nem sempre foi linear, e a IA passou por períodos de entusiasmo e desilusão, conhecidos como \"invernos da IA\"."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Este documento explora a jornada da IA desde suas origens até os desenvolvimentos mais recentes, incluindo suas aplicações, fornecedores líderes e ferramentas essenciais."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Conversação com o assistente\n",
        "\n",
        "continuar = True\n",
        "print('Olá, sou um chatbot e vou responder perguntas sobre o arquivo.','\\n')\n",
        "print('Para sair digite: sair','\\n')\n",
        "resposta_chat = \"\"\n",
        "resposta_gemini = \"\"\n",
        "while (continuar == True):\n",
        "    print('Faça aqui sua pergunta: ')\n",
        "    texto_usuario = input()\n",
        "    texto_usuario = texto_usuario.lower()\n",
        "    if (texto_usuario != 'sair'):\n",
        "        resposta_chat = responder(preprocessamento(texto_usuario))\n",
        "        resposta_gemini = chat.send_message(texto_usuario)\n",
        "\n",
        "        display(HTML(f'<h1>Resposta Chat</h1>'))\n",
        "        display(HTML(f'<br>'))\n",
        "        display(HTML(f'{resposta_chat}'))\n",
        "\n",
        "        display(HTML(f'<br>'))\n",
        "        display(HTML(f'<h1>Resposta Gemini</h1>'))\n",
        "        display(HTML(f'{resposta_gemini.text}'))\n",
        "        display(HTML(f'<br>'))\n",
        "\n",
        "    else:\n",
        "        continuar = False\n",
        "        print('Chatbot: Até breve!')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 531
        },
        "id": "F1M7iWukFfSb",
        "outputId": "622b1ddf-c49f-4d04-de94-0e6d6eb219a7"
      },
      "execution_count": 36,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Olá, sou um chatbot e vou responder perguntas sobre o arquivo. \n",
            "\n",
            "Para sair digite: sair \n",
            "\n",
            "Faça aqui sua pergunta: \n",
            "o que é pytorch\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<h1>Resposta Chat</h1>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "- PyTorch: Uma biblioteca de aprendizado de máquina de código aberto desenvolvida pelo Facebook."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<h1>Resposta Gemini</h1>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "**PyTorch** é uma biblioteca de aprendizado de máquina de código aberto baseada em Python desenvolvida pelo Facebook AI Research (FAIR). É projetada para fornecer uma interface de alto nível e fácil de usar para criar e treinar modelos de aprendizado profundo.\n",
              "\n",
              "**Principais recursos:**\n",
              "\n",
              "* **Tensorial:** O PyTorch representa dados como tensores, que são matrizes multidimensionais que podem ser operadas por meio de operações matemáticas.\n",
              "* **Diferenciação automática:** Ele fornece suporte para diferenciação automática, que calcula gradientes de funções com eficiência, facilitando o treinamento de modelos.\n",
              "* **Paralelização:** O PyTorch oferece suporte à execução paralela em GPUs e CPUs, permitindo treinamento e inferência mais rápidos.\n",
              "* **Ecosistema abrangente:** Ele tem um ecossistema de ferramentas e bibliotecas abrangente, incluindo pacotes de otimização, manipulação de dados e visualização.\n",
              "* **Fácil de usar:** O PyTorch tem uma API intuitiva e bem documentada, tornando-o acessível a usuários de todos os níveis.\n",
              "\n",
              "**Aplicações:**\n",
              "\n",
              "O PyTorch é amplamente utilizado em uma variedade de aplicações de aprendizado de máquina, incluindo:\n",
              "\n",
              "* Visão computacional (classificação de imagens, detecção de objetos)\n",
              "* Processamento de linguagem natural (processamento de texto, tradução de idiomas)\n",
              "* Aprendizado por reforço (jogos, robótica)\n",
              "* Aprendizado de representação (codificadores automáticos, redes adversárias generativas)\n",
              "\n",
              "**Vantagens:**\n",
              "\n",
              "* **Flexibilidade:** O PyTorch oferece um alto grau de flexibilidade, permitindo que os usuários criem modelos personalizados e experimentem diferentes arquiteturas.\n",
              "* **Desempenho:** Ele é otimizado para desempenho, aproveitando as GPUs para acelerar o treinamento e a inferência.\n",
              "* **Comunidade ativa:** O PyTorch tem uma comunidade ativa de desenvolvedores e usuários que fornecem suporte e contribuem com novas funcionalidades.\n",
              "\n",
              "**Desvantagens:**\n",
              "\n",
              "* **Curva de aprendizado:** Embora seja fácil de usar, o PyTorch pode ter uma curva de aprendizado mais íngreme para iniciantes em aprendizado de máquina.\n",
              "* **Dependências:** O PyTorch depende de outras bibliotecas, como NumPy e CUDA, que podem exigir instalação e configuração adicionais."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Faça aqui sua pergunta: \n",
            "sair\n",
            "Chatbot: Até breve!\n"
          ]
        }
      ]
    }
  ]
}